# üè¶ Credit Risk Scoring Pipeline

![Apache Spark](https://img.shields.io/badge/Apache%20Spark-E25A1C?style=flat&logo=apachespark&logoColor=white) ![Apache Kafka](https://img.shields.io/badge/Apache%20Kafka-231F20?style=flat&logo=apachekafka&logoColor=white) ![HBase](https://img.shields.io/badge/Apache%20HBase-204178?style=flat&logo=apachehbase&logoColor=white) ![PostgreSQL](https://img.shields.io/badge/PostgreSQL-336791?style=flat&logo=postgresql&logoColor=white) ![Docker](https://img.shields.io/badge/Docker-2496ED?style=flat&logo=docker&logoColor=white)

H·ªá th·ªëng ƒë√°nh gi√° r·ªßi ro t√≠n d·ª•ng (Credit Scoring) theo ki·∫øn tr√∫c Lambda: x·ª≠ l√Ω l√¥ (Batch) ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh v√† x·ª≠ l√Ω lu·ªìng (Streaming) ƒë·ªÉ d·ª± ƒëo√°n th·ªùi gian th·ª±c.

---

## M·ª•c l·ª•c
- [Y√™u c·∫ßu h·ªá th·ªëng](#y√™u-c·∫ßu-h·ªá-th·ªëng)
- [Quickstart](#quickstart)
- [Batch (Training)](#batch-training)
- [Realtime (Inference)](#realtime-inference)
- [Serving (Spring Boot)](#serving-spring-boot)
- [Troubleshooting & Tips](#troubleshooting--tips)
- [Li√™n h·ªá](#li√™n-h·ªá)

---

## Y√™u c·∫ßu h·ªá th·ªëng

- Docker & Docker Compose
- Java (cho Spark/Spring n·∫øu ch·∫°y c·ª•c b·ªô)
- PowerShell (Windows) ƒë·ªÉ ch·∫°y v√≠ d·ª• PowerShell ‚Äî c√°c l·ªánh shell ƒë·ªÅu t∆∞∆°ng th√≠ch n·∫øu d√πng WSL ho·∫∑c Git Bash

## Quickstart

1. Build images v√† kh·ªüi ch·∫°y to√†n b·ªô d·ªãch v·ª•:

```powershell
docker-compose build
docker-compose up -d
docker ps
```

2. Ki·ªÉm tra c√°c giao di·ªán qu·∫£n tr·ªã:

| Service | URL / Access | Ch·ª©c nƒÉng |
| :--- | :--- | :--- |
| **Spark Master** | [http://localhost:8080](http://localhost:8080) | Qu·∫£n l√Ω Cluster & Job |
| **HDFS NameNode** | [http://localhost:9870](http://localhost:9870) | Qu·∫£n l√Ω File System |
| **Kafka UI** | [http://localhost:8083](http://localhost:8083) | (N·∫øu c√≥ c√†i Kafka UI) |
| **Spring Boot** | [http://localhost:8085](http://localhost:8085) | API Serving |
| **PostgreSQL** | Port 5432 | Database l∆∞u k·∫øt qu·∫£ batch |

## Batch (Training)

Quy tr√¨nh: HDFS ‚ûú Spark ML (XGBoost) ‚ûú PostgreSQL

1) Upload d·ªØ li·ªáu l√™n HDFS:

```bash
# copy t·ª´ host v√†o container namenode
docker cp "Path_to_file/train.csv" namenode:/tmp/train.csv
docker cp "Path_to_file/test.csv" namenode:/tmp/test.csv

docker exec -it namenode bash
hdfs dfs -mkdir -p /data
hdfs dfs -put -f /tmp/train.csv /data/train.csv
hdfs dfs -put -f /tmp/test.csv  /data/test.csv
hdfs dfs -ls /data # Ki·ªÉm tra xem ƒë√£ c√≥ data ch∆∞a
```

2) Ch·∫°y `train.py` tr√™n Spark Master:

```bash
docker exec -it spark-master bash
/opt/spark/bin/spark-submit \
  --master spark://spark-master:7077 \
  --conf spark.pyspark.python=python3 \
  --conf spark.pyspark.driver.python=python3 \
  --conf spark.executor.memory=2g \
  --conf spark.driver.memory=2g \
  --conf spark.sql.shuffle.partitions=32 \
  --conf spark.task.cpus=1 \
  /opt/app/train.py
```

3) Ki·ªÉm tra k·∫øt qu·∫£ trong PostgreSQL:

```bash
docker exec -it postgres bash
psql -U finuser -d finrisk
SELECT * FROM public.spark_train_scores LIMIT 20;
```

## Realtime (Inference)

### Ingestion (API g·ª≠i d·ªØ li·ªáu v√†o Kafka)

```bash
docker exec -it kafka bash -lc "kafka-topics --create --topic credit_applications --bootstrap-server kafka:9092 --partitions 3 --replication-factor 1 || true"
docker-compose build ingestion-api
docker-compose up -d ingestion-api
```

G·ª≠i y√™u c·∫ßu m·∫´u (PowerShell):

```powershell
Invoke-RestMethod `
  -Uri "http://localhost:8000/api/loan-application?fraud_rate=0.01" `
  -Method Post `
  -ContentType "application/json" `
  -Body "{}"
```

Ho·∫∑c d√πng script Python:

```bash
pip install requests
python send_request.py
```

### Streaming layer (Spark Structured Streaming)

1) T·∫°o topic output:

```bash
docker exec -it kafka bash -lc "kafka-topics --create --topic credit_scores --bootstrap-server kafka:9092 --partitions 3 --replication-factor 1 || true"
```

2) (N·∫øu c·∫ßn) X√≥a checkpoint khi ch·∫°y l·∫°i streaming job:

```bash
docker exec -it namenode bash
hdfs dfs -rm -r /checkpoints/credit_scoring_v3 || true
```

3) Ch·∫°y `streaming_score.py` tr√™n Spark Master (ƒë·∫£m b·∫£o jar Kafka trong `/opt/spark/jars`):

```bash
docker exec -it spark-master bash
/opt/spark/bin/spark-submit \
  --master spark://spark-master:7077 \
  --conf spark.pyspark.python=python3 \
  --conf spark.pyspark.driver.python=python3 \
  --conf spark.executor.memory=3g \
  --conf spark.driver.memory=3g \
  --conf spark.executor.cores=1 \
  --conf spark.task.cpus=1 \
  --conf spark.sql.shuffle.partitions=6 \
  --conf spark.driver.extraClassPath=/opt/spark/jars/* \
  --conf spark.executor.extraClassPath=/opt/spark/jars/* \
  /opt/app/streaming_score.py
```

Ki·ªÉm tra Kafka UI: topic `credit_applications` (input) v√† `credit_scores` (output).

### HBase (l∆∞u realtime scores)

```bash
docker exec -it hbase bash
hbase shell
create 'realtime_scores', 'score', 'meta'
scan 'realtime_scores', {LIMIT => 5}
```

## Serving (Spring Boot)

```bash
docker compose build spring-boot-api
docker compose up -d spring-boot-api
docker ps
```

Check health: `http://localhost:8085/api/health`

Get score: `http://localhost:8085/api/score/<SK_ID_CURR>`

## Troubleshooting & Tips

- N·∫øu container kh√¥ng kh·ªüi ƒë·ªông: xem logs `docker-compose logs <service>`.
- Spark kh√¥ng th·∫•y Kafka jars: ki·ªÉm tra `/opt/spark/jars` trong container `spark-master`.
- L·ªói HDFS permission: ki·ªÉm tra quy·ªÅn ho·∫∑c d√πng `hdfs dfs -chmod`.
- Streaming kh√¥ng ra `credit_scores`: ki·ªÉm tra checkpoint, offsets v√† logs c·ªßa Spark.

## Li√™n h·ªá

- Author: d·ª± √°n n·ªôi b·ªô ‚Äî ch·ªânh s·ª≠a theo nhu c·∫ßu c·ªßa team.